{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3c9e4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adf6dfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torchinfo import summary\n",
    "from pytorch_lightning.loggers import TensorBoardLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ed5ab87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmark.data import read_tep_data\n",
    "from benchmark.deep_learning import TimeSeriesClassifier\n",
    "from benchmark.deep_learning import FullyConvolutionalEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822d30b5",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc48fb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = [1, 3, 4, 5, 6]\n",
    "target = [2,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07e7ed6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs, ys = read_tep_data(\n",
    "    base_path='../tep_data/benchmark/',\n",
    "    modes=sources,\n",
    "    normalization=\"standardization\",\n",
    "    return_domain=False,\n",
    "    as_list=False,\n",
    "    channels_first=False,\n",
    "    one_hot_labels=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e221f896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([14444, 600, 34]), torch.Size([14444]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xs.shape, ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95618f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt, yt = read_tep_data(\n",
    "    base_path='../tep_data/benchmark/',\n",
    "    modes=target,\n",
    "    normalization=\"standardization\",\n",
    "    return_domain=False,\n",
    "    as_list=False,\n",
    "    channels_first=False,\n",
    "    one_hot_labels=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc849404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2845, 600, 34]), torch.Size([2845]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xt.shape, yt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55271ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dataset = torch.utils.data.TensorDataset(Xs, ys)\n",
    "src_dataloader = torch.utils.data.DataLoader(\n",
    "    src_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "tgt_dataset = torch.utils.data.TensorDataset(Xt, yt)\n",
    "tgt_dataloader = torch.utils.data.DataLoader(\n",
    "    tgt_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee4fc56",
   "metadata": {},
   "source": [
    "## Creating the neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e43ca760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "544"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "34 * 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "420c78d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 emb_size: int,\n",
    "                 dropout: float,\n",
    "                 maxlen: int = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: torch.Tensor):\n",
    "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89bbbb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "nhead = 8\n",
    "head_dim = 32\n",
    "d_model = nhead * head_dim\n",
    "\n",
    "embedding_layer = torch.nn.Linear(34, d_model)\n",
    "pos_encoding = PositionalEncoding(emb_size=d_model, dropout=0.1, maxlen=600)\n",
    "\n",
    "layer1 = torch.nn.TransformerEncoderLayer(\n",
    "    d_model=d_model,\n",
    "    nhead=nhead,\n",
    "    dim_feedforward=512,\n",
    "    dropout=0.1,\n",
    "    activation='relu',\n",
    "    batch_first=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee1cab4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = embedding_layer(Xs[:16])\n",
    "embedding = pos_encoding(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1efe2dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 600, 256])\n"
     ]
    }
   ],
   "source": [
    "print(embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f28812a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(torch.nn.Module):\n",
    "    def __init__(self, d_input, head_dim, nhead, dim_feedforward, dropout=0.1, seq_len=600,\n",
    "                 num_layers=6, reduction='avg'):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        d_model = head_dim * nhead\n",
    "        self.embedding_layer = torch.nn.Linear(d_input, d_model)\n",
    "        self.pos_encoding = PositionalEncoding(emb_size=d_model, dropout=dropout, maxlen=seq_len)\n",
    "        layer = torch.nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            activation='relu',\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = torch.nn.TransformerEncoder(\n",
    "            layer, num_layers\n",
    "        )\n",
    "        assert reduction.lower() in ['last', 'avg']\n",
    "        self.reduction = reduction.lower()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        e = self.pos_encoding(\n",
    "            self.embedding_layer(x))\n",
    "        h = self.transformer(e)\n",
    "        \n",
    "        if self.reduction == 'last':\n",
    "            h = h[:, -1, :]\n",
    "        if self.reduction == 'avg':\n",
    "            h = h.mean(dim=1)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1f01ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = TransformerEncoder(\n",
    "    d_input=34,\n",
    "    head_dim=16,\n",
    "    nhead=8,\n",
    "    dim_feedforward=256,\n",
    "    dropout=0.1,\n",
    "    seq_len=600,\n",
    "    num_layers=6,\n",
    "    reduction='last'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "723a9955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                                            Param #\n",
       "==========================================================================================\n",
       "TransformerEncoder                                                --\n",
       "├─Linear: 1-1                                                     4,480\n",
       "├─PositionalEncoding: 1-2                                         --\n",
       "│    └─Dropout: 2-1                                               --\n",
       "├─TransformerEncoder: 1-3                                         --\n",
       "│    └─ModuleList: 2-2                                            --\n",
       "│    │    └─TransformerEncoderLayer: 3-1                          132,480\n",
       "│    │    └─TransformerEncoderLayer: 3-2                          132,480\n",
       "│    │    └─TransformerEncoderLayer: 3-3                          132,480\n",
       "│    │    └─TransformerEncoderLayer: 3-4                          132,480\n",
       "│    │    └─TransformerEncoderLayer: 3-5                          132,480\n",
       "│    │    └─TransformerEncoderLayer: 3-6                          132,480\n",
       "==========================================================================================\n",
       "Total params: 799,360\n",
       "Trainable params: 799,360\n",
       "Non-trainable params: 0\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(encoder, input_shape=(16, 600, 34))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcace77e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 128])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder(Xs[:16]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af0a292e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = torch.nn.Linear(128, 29)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ca8782",
   "metadata": {},
   "source": [
    "## Training with Pytorch Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b3245b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 70\n",
    "momentum = 0.9\n",
    "l2_penalty = 0.0\n",
    "learning_rate = 1e-4\n",
    "optimizer_name = 'adam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2475c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TimeSeriesClassifier(encoder=encoder,\n",
    "                             clf=clf,\n",
    "                             n_classes=29,\n",
    "                             loss_fn=torch.nn.CrossEntropyLoss(),\n",
    "                             input_shape=(Xs.shape[1:]),\n",
    "                             learning_rate=learning_rate,\n",
    "                             l2_penalty=l2_penalty,\n",
    "                             momentum=momentum,\n",
    "                             optimizer_name=optimizer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e56572c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = f\"../models/logs/{sources}->{target[0]}\"\n",
    "log_name = \"multi_source_only_baseline_transformer_last\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "501b1314",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = TensorBoardLogger(save_dir=log_dir, name=log_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b5c8891",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA RTX A1000 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Missing logger folder: ../models/logs/[1, 3, 4, 5, 6]->2/multi_source_only_baseline_transformer_last\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type               | Params | In sizes      | Out sizes\n",
      "---------------------------------------------------------------------------\n",
      "0 | clf     | Linear             | 3.7 K  | [16, 128]     | [16, 29] \n",
      "1 | encoder | TransformerEncoder | 799 K  | [16, 600, 34] | [16, 128]\n",
      "2 | loss_fn | CrossEntropyLoss   | 0      | ?             | ?        \n",
      "---------------------------------------------------------------------------\n",
      "803 K     Trainable params\n",
      "0         Non-trainable params\n",
      "803 K     Total params\n",
      "3.212     Total estimated model params size (MB)\n",
      "2024-06-13 13:11:17.121798: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-13 13:11:17.122885: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-13 13:11:17.142690: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-13 13:11:17.490216: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/efernand/anaconda3/envs/OptimalTransport/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:478: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "  rank_zero_warn(\n",
      "/home/efernand/anaconda3/envs/OptimalTransport/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/efernand/anaconda3/envs/OptimalTransport/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50fe4bcb833e4e498a9dbde0b16ecf44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/efernand/anaconda3/envs/OptimalTransport/lib/python3.8/site-packages/pytorch_lightning/trainer/call.py:54: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=n_epochs,\n",
    "    accelerator='gpu',\n",
    "    logger=logger,\n",
    "    enable_checkpointing=True,\n",
    "    enable_progress_bar=True)\n",
    "trainer.fit(model,\n",
    "            src_dataloader,\n",
    "            tgt_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355d4bab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:OptimalTransport] *",
   "language": "python",
   "name": "conda-env-OptimalTransport-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
